{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spatial_factorization\n",
    "from data_loader import load_nsf_slideseq_subset_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SpatialFactorization in module spatial_factorization.sf:\n",
      "\n",
      "class SpatialFactorization(tensorflow.python.module.module.Module)\n",
      " |  SpatialFactorization(J, L, Z, lik='poi', psd_kernel=<class 'tensorflow_probability.python.math.psd_kernels.matern.MaternThreeHalves'>, nugget=1e-05, length_scale=0.1, disp='default', nonneg=False, isotropic=True, feature_means=None, **kwargs)\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      SpatialFactorization\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.trackable.base.Trackable\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, J, L, Z, lik='poi', psd_kernel=<class 'tensorflow_probability.python.math.psd_kernels.matern.MaternThreeHalves'>, nugget=1e-05, length_scale=0.1, disp='default', nonneg=False, isotropic=True, feature_means=None, **kwargs)\n",
      " |      Non-negative process factorization\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      J : integer scalar\n",
      " |          Number of features in the multivariate outcome.\n",
      " |      L : integer scalar\n",
      " |          Number of desired latent Gaussian processes.\n",
      " |      T : integer scalar\n",
      " |          Number of desired non-spatial latent factors\n",
      " |      Z : 2D numpy array\n",
      " |          Coordinates of inducing point locations in input space.\n",
      " |          First dimension: 'M' is number of inducing points.\n",
      " |          Second dimension: 'D' is dimensionality of input to GP.\n",
      " |          More inducing points= slower but more accurate inference.\n",
      " |      lik: likelihood (Poisson or Gaussian)\n",
      " |      disp: overdispersion parameter initialization.\n",
      " |      --for Gaussian likelihood, the scale (stdev) parameter\n",
      " |      --for negative binomial likelihood, the parameter phi such that\n",
      " |        var=mean+phi*mean^2, i.e. phi->0 corresponds to Poisson, phi=1 to geometric\n",
      " |      --for Poisson likelihood, this parameter is ignored and set to None\n",
      " |      psd_kernel : an object of class PositiveSemidefiniteKernel, must accept a\n",
      " |          length_scale parameter.\n",
      " |      feature_means : if input data is centered (for lik='gau', nonneg=False)\n",
      " |\n",
      " |  elbo_avg(self, X, Y, sz=1, S=1, Ntot=None, chol=True)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of spatial coordinates (NxD)\n",
      " |          **OR** a tuple of spatial coordinates, multivariate outcomes,\n",
      " |          and size factors (convenient for minibatches from tensor slices)\n",
      " |      Y : numpy array of multivariate outcomes (NxJ)\n",
      " |          If Y is None then X must be a tuple of length three\n",
      " |      sz : size factors, optional\n",
      " |          vector of length N, typically the rowSums or rowMeans of Y.\n",
      " |          If X is a tuple then this is ignored as sz is expected in the third\n",
      " |          element of the X tuple.\n",
      " |      S : integer, optional\n",
      " |          Number of random GP function evaluations to use. The default is 1.\n",
      " |          Larger S=more accurate approximation to true ELBO but slower\n",
      " |      Ntot : total number of observations in full dataset\n",
      " |          This is needed when X,Y,sz are a minibatch from the full data\n",
      " |          If Ntot is None, we assume X,Y,sz provided are the full data NOT a minibatch.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      The numeric evidence lower bound value, divided by Ntot.\n",
      " |\n",
      " |  eval_Kuu_chol(self, kernel=None)\n",
      " |\n",
      " |  eval_kl_term(self, mu_z, Kuu_chol)\n",
      " |      KL divergence from the prior distribution to the variational distribution.\n",
      " |      This is one component of the ELBO:\n",
      " |      ELBO=expected log-likelihood - sum(kl_terms)\n",
      " |      qpars: a tuple containing (mu_z,Kuu_chol)\n",
      " |      qpars can be obtained by calling self.get_variational_params()\n",
      " |      mu_z is the GP mean function at all inducing points (dimension: LxM)\n",
      " |      Kuu_chol is the cholesky lower triangular of the kernel matrix of all inducing points.\n",
      " |      Its dimension is LxMxM\n",
      " |      where L = number of latent dimensions and M = number of inducing points.\n",
      " |\n",
      " |  generate_pickle_path(self, sz, base=None)\n",
      " |      sz : str\n",
      " |        Indicate what type of size factors are used (eg 'none' or 'scanpy').\n",
      " |      base : str, optional\n",
      " |        Parent directory for saving pickle files. The default is cwd.\n",
      " |\n",
      " |  get_Kuu_chol(self, kernel=None, from_cache=False)\n",
      " |\n",
      " |  get_dims(self)\n",
      " |\n",
      " |  get_kernel(self)\n",
      " |\n",
      " |  get_loadings(self)\n",
      " |\n",
      " |  get_mu_z(self)\n",
      " |\n",
      " |  init_loadings(self, Y, X=None, sz=1, **kwargs)\n",
      " |      Use either PCA or NMF to initialize the loadings matrix from data Y\n",
      " |\n",
      " |  predict(self, Dtr, Dval=None, S=10)\n",
      " |      Here Dtr,Dval should be raw counts (not normalized or log-transformed)\n",
      " |\n",
      " |      returns the predicted training data mean and validation data mean\n",
      " |      on the original count scale\n",
      " |\n",
      " |  sample_latent_GP_funcs(self, X, S=1, kernel=None, mu_z=None, Kuu_chol=None, chol=True)\n",
      " |      Draw random samples of the latent variational GP function values \"F\"\n",
      " |      based on spatial coordinates X.\n",
      " |      The sampling comes from the variational approximation to the posterior.\n",
      " |      This function is needed to compute the expected log-likelihood term of the\n",
      " |      ELBO.\n",
      " |      X is a numpy array with shape NxD\n",
      " |      N=number of observations\n",
      " |      D=number of spatial dimensions\n",
      " |      The first dimension can be observations from a minibatch.\n",
      " |      S is the number of random samples to draw from latent GPs\n",
      " |      logscale: if False the function vals are exponentiated before returning\n",
      " |      i.e. they are positive valued random functions.\n",
      " |      If logscale=True (default), the functions are real-valued\n",
      " |\n",
      " |  sample_predictive_mean(self, X, sz=1, S=1, kernel=None, mu_z=None, Kuu_chol=None, chol=True)\n",
      " |      See sample_latent_variational_GP_funcs for X,S definitions\n",
      " |      sz is a tensor of shape (N,1) of size factors.\n",
      " |      Typically sz would be the rowSums or rowMeans of the outcome matrix Y.\n",
      " |\n",
      " |  set_loadings(self, Wnew)\n",
      " |\n",
      " |  train_step(self, D, optimizer, optimizer_k, S=1, Ntot=None, chol=True)\n",
      " |      Executes one training step and returns the loss.\n",
      " |      D is training data: a tensorflow dataset (from slices) of (X,Y,sz)\n",
      " |      This function computes the loss and gradients, and uses the latter to\n",
      " |      update the model's parameters.\n",
      " |\n",
      " |  validation_step(self, D, S=1, chol=False)\n",
      " |      Compute the validation loss on held-out data D\n",
      " |      D is a tensorflow dataset (from slices) of (X,Y,sz)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |\n",
      " |  with_name_scope(method)\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |\n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |\n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |\n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |\n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |\n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |\n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |\n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |\n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |\n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |\n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |\n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |\n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |\n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |\n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |\n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |\n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |\n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |\n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |\n",
      " |  variables\n",
      " |      Sequence of variables owned by this module and its submodules.\n",
      " |\n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |\n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.trackable.autotrackable.AutoTrackable:\n",
      " |\n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |\n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(spatial_factorization.SpatialFactorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_nsf_slideseq_subset_genes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 36536 × 2000\n",
       "    obs: 'orig.ident', 'nCount_Spatial', 'nFeature_Spatial', 'cells', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt', 'n_counts', 'sizefactor'\n",
       "    var: 'deviance_poisson', 'mt', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells'\n",
       "    uns: 'log1p'\n",
       "    obsm: 'spatial'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3487.9 , 4317.3 ],\n",
       "       [3549.9 ,  889.95],\n",
       "       [2356.7 , 1789.3 ],\n",
       "       ...,\n",
       "       [4269.8 , 4370.3 ],\n",
       "       [1408.3 , 2597.1 ],\n",
       "       [5093.4 , 3226.6 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.obsm[\"spatial\"][np.random.choice(data.obsm[\"spatial\"].shape[0], 3000, replace=False)].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error processing property 'trvars_kernel' of _TupleWrapper((<tf.Variable 'gp_kernel/amplitude:0' shape=(10,) dtype=float32, numpy=\narray([0.54132485, 0.54132485, 0.54132485, 0.54132485, 0.54132485,\n       0.54132485, 0.54132485, 0.54132485, 0.54132485, 0.54132485],\n      dtype=float32)>, <tf.Variable 'gp_kernel/length_scale:0' shape=(10,) dtype=float32, numpy=\narray([-2.2521687, -2.2521687, -2.2521687, -2.2521687, -2.2521687,\n       -2.2521687, -2.2521687, -2.2521687, -2.2521687, -2.2521687],\n      dtype=float32)>))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/data/walter/miniconda3/envs/nsf/lib/python3.12/site-packages/tensorflow/python/module/module.py:422\u001b[0m, in \u001b[0;36m_flatten_module\u001b[0;34m(module, recursive, predicate, attribute_traversal_key, attributes_to_ignore, with_path, expand_composites, module_path, seen, recursion_stack)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expand_composites:\n\u001b[0;32m--> 422\u001b[0m   leaves \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_flatten_non_variable_composites_with_tuple_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/data/walter/miniconda3/envs/nsf/lib/python3.12/site-packages/tensorflow/python/module/module.py:345\u001b[0m, in \u001b[0;36m_flatten_non_variable_composites_with_tuple_path\u001b[0;34m(structure, path_prefix)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Flattens composite tensors with tuple path expect variables.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path, child \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_with_tuple_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    346\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(child, composite_tensor\u001b[38;5;241m.\u001b[39mCompositeTensor) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    347\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m _is_variable(child)):\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/data/walter/miniconda3/envs/nsf/lib/python3.12/site-packages/tensorflow/python/util/nest.py:1283\u001b[0m, in \u001b[0;36mflatten_with_tuple_paths\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of `(tuple_path, atom)` tuples.\u001b[39;00m\n\u001b[1;32m   1266\u001b[0m \n\u001b[1;32m   1267\u001b[0m \u001b[38;5;124;03mThe order of pairs produced matches that of `nest.flatten`. This allows you\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;124;03m  `atom` within `structure`.\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myield_flat_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_composites\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m                \u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_composites\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/walter/miniconda3/envs/nsf/lib/python3.12/site-packages/tensorflow/python/util/nest.py:1229\u001b[0m, in \u001b[0;36myield_flat_paths\u001b[0;34m(nest, expand_composites)\u001b[0m\n\u001b[1;32m   1228\u001b[0m is_nested_fn \u001b[38;5;241m=\u001b[39m _is_nested_or_composite \u001b[38;5;28;01mif\u001b[39;00m expand_composites \u001b[38;5;28;01melse\u001b[39;00m is_nested\n\u001b[0;32m-> 1229\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myield_flat_up_to\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_nested_fn\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\n",
      "File \u001b[0;32m/data/walter/miniconda3/envs/nsf/lib/python3.12/site-packages/tensorflow/python/util/nest_util.py:1160\u001b[0m, in \u001b[0;36myield_flat_up_to\u001b[0;34m(modality, shallow_tree, input_tree, is_nested_fn, path)\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1160\u001b[0m   \u001b[38;5;28;01myield from\u001b[39;00m _tf_core_yield_flat_up_to(\n\u001b[1;32m   1161\u001b[0m       shallow_tree, input_tree, is_nested_fn, path\n\u001b[1;32m   1162\u001b[0m   )\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n",
      "File \u001b[0;32m/data/walter/miniconda3/envs/nsf/lib/python3.12/site-packages/tensorflow/python/util/nest_util.py:1192\u001b[0m, in \u001b[0;36m_tf_core_yield_flat_up_to\u001b[0;34m(shallow_tree, input_tree, is_nested_fn, path)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1192\u001b[0m   input_tree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_tf_core_yield_sorted_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tree\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[1;32m   1194\u001b[0m       shallow_key,\n\u001b[1;32m   1195\u001b[0m       shallow_subtree,\n\u001b[1;32m   1196\u001b[0m   ) \u001b[38;5;129;01min\u001b[39;00m _tf_core_yield_sorted_items(shallow_tree):\n",
      "File \u001b[0;32m/data/walter/miniconda3/envs/nsf/lib/python3.12/site-packages/tensorflow/python/util/nest_util.py:368\u001b[0m, in \u001b[0;36m_tf_core_yield_sorted_items\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    367\u001b[0m   \u001b[38;5;28;01myield\u001b[39;00m iterable\u001b[38;5;241m.\u001b[39mvalue_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, iterable\u001b[38;5;241m.\u001b[39m_component_specs  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCustomNestProtocol\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    369\u001b[0m   flat_component \u001b[38;5;241m=\u001b[39m iterable\u001b[38;5;241m.\u001b[39m__tf_flatten__()[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/data/walter/miniconda3/envs/nsf/lib/python3.12/typing.py:1921\u001b[0m, in \u001b[0;36m_ProtocolMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1921\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[43mgetattr_static\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "File \u001b[0;32m/data/walter/miniconda3/envs/nsf/lib/python3.12/inspect.py:1860\u001b[0m, in \u001b[0;36mgetattr_static\u001b[0;34m(obj, attr, default)\u001b[0m\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (dict_attr \u001b[38;5;129;01mis\u001b[39;00m _sentinel \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m         \u001b[38;5;28mtype\u001b[39m(dict_attr) \u001b[38;5;129;01mis\u001b[39;00m types\u001b[38;5;241m.\u001b[39mMemberDescriptorType):\n\u001b[0;32m-> 1860\u001b[0m         instance_result \u001b[38;5;241m=\u001b[39m \u001b[43m_check_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/data/walter/miniconda3/envs/nsf/lib/python3.12/inspect.py:1796\u001b[0m, in \u001b[0;36m_check_instance\u001b[0;34m(obj, attr)\u001b[0m\n\u001b[1;32m   1795\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1796\u001b[0m     instance_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__dict__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: this __dict__ descriptor does not support '_TupleWrapper' objects",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mspatial_factorization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSpatialFactorizationHybrid\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mN\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mJ\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobsm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspatial\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobsm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspatial\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/walter/miniconda3/envs/nsf/lib/python3.12/site-packages/spatial_factorization/sfh.py:56\u001b[0m, in \u001b[0;36mSpatialFactorizationHybrid.__init__\u001b[0;34m(self, N, J, L, Z, T, lik, nonneg, psd_kernel, isotropic, nugget, length_scale, disp, feature_means, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonneg \u001b[38;5;241m=\u001b[39m nonneg\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disp0 \u001b[38;5;241m=\u001b[39m disp\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspat \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSpatialFactorization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnonneg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnonneg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlik\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlik\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43misotropic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43misotropic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mpsd_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpsd_kernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnugget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnugget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mlength_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlength_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mfeature_means\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#spatial\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsp \u001b[38;5;241m=\u001b[39m cf\u001b[38;5;241m.\u001b[39mCountFactorization(N, J, L\u001b[38;5;241m-\u001b[39mT, lik\u001b[38;5;241m=\u001b[39mlik, nonneg\u001b[38;5;241m=\u001b[39mnonneg,\n\u001b[1;32m     62\u001b[0m                                  disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feature_means\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;66;03m#nonspatial\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisp \u001b[38;5;241m=\u001b[39m likelihoods\u001b[38;5;241m.\u001b[39minit_lik(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlik, J, disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disp0, dtp\u001b[38;5;241m=\u001b[39mdtp)\n",
      "File \u001b[0;32m/data/walter/miniconda3/envs/nsf/lib/python3.12/site-packages/spatial_factorization/sf.py:98\u001b[0m, in \u001b[0;36mSpatialFactorization.__init__\u001b[0;34m(self, J, L, Z, lik, psd_kernel, nugget, length_scale, disp, nonneg, isotropic, feature_means, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m#likelihood parameters, set defaults\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disp0 \u001b[38;5;241m=\u001b[39m disp\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_misc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mKuu_chol \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_Kuu_chol(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_kernel()), dtype\u001b[38;5;241m=\u001b[39mdtp, trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlik\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgau\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonneg:\n",
      "File \u001b[0;32m/data/walter/miniconda3/envs/nsf/lib/python3.12/site-packages/spatial_factorization/sf.py:129\u001b[0m, in \u001b[0;36mSpatialFactorization._init_misc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m#stuff to facilitate caching\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrvars_kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m.\u001b[39mname[:\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgp_kernel/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrvars_nonkernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m.\u001b[39mname[:\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgp_kernel/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misotropic:\n\u001b[1;32m    131\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpsd_kernel(amplitude\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamplitude, length_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_scale)\n",
      "File \u001b[0;32m/data/walter/miniconda3/envs/nsf/lib/python3.12/site-packages/tensorflow/python/module/module.py:170\u001b[0m, in \u001b[0;36mModule.trainable_variables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrainable_variables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Sequence of trainable variables owned by this module and its submodules.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m  Note: this method uses reflection to find variables on the current instance\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m    first).\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_is_trainable_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/walter/miniconda3/envs/nsf/lib/python3.12/site-packages/tensorflow/python/module/module.py:426\u001b[0m, in \u001b[0;36m_flatten_module\u001b[0;34m(module, recursive, predicate, attribute_traversal_key, attributes_to_ignore, with_path, expand_composites, module_path, seen, recursion_stack)\u001b[0m\n\u001b[1;32m    424\u001b[0m     leaves \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten_with_tuple_paths(prop)\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m cause:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m--> 426\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing property \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    427\u001b[0m       key, prop)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcause\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m leaf_path, leaf \u001b[38;5;129;01min\u001b[39;00m leaves:\n\u001b[1;32m    430\u001b[0m   leaf_path \u001b[38;5;241m=\u001b[39m (key,) \u001b[38;5;241m+\u001b[39m leaf_path\n",
      "\u001b[0;31mValueError\u001b[0m: Error processing property 'trvars_kernel' of _TupleWrapper((<tf.Variable 'gp_kernel/amplitude:0' shape=(10,) dtype=float32, numpy=\narray([0.54132485, 0.54132485, 0.54132485, 0.54132485, 0.54132485,\n       0.54132485, 0.54132485, 0.54132485, 0.54132485, 0.54132485],\n      dtype=float32)>, <tf.Variable 'gp_kernel/length_scale:0' shape=(10,) dtype=float32, numpy=\narray([-2.2521687, -2.2521687, -2.2521687, -2.2521687, -2.2521687,\n       -2.2521687, -2.2521687, -2.2521687, -2.2521687, -2.2521687],\n      dtype=float32)>))"
     ]
    }
   ],
   "source": [
    "model = spatial_factorization.SpatialFactorizationHybrid(\n",
    "    N = data.n_obs,\n",
    "    J = 2000,\n",
    "    L = 20,\n",
    "    Z = data.obsm[\"spatial\"][np.random.choice(data.obsm[\"spatial\"].shape[0], 3000, replace=False)].astype(\"float32\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "famo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
